{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import hvplot.xarray\n",
    "from distributed import Client\n",
    "import numpy as np\n",
    "import fsspec\n",
    "import pandas as pd\n",
    "from scipy.stats.mstats import plotting_positions\n",
    "import panel as pn\n",
    "from holoviews import opts\n",
    "from dask.distributed import progress\n",
    "import s3fs\n",
    "import dask\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Débits stochastiques laminés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 's3://prsim/laminage/09995'\n",
    "storage_options = {'endpoint_url': 'https://s3.us-east-1.wasabisys.com'}\n",
    "fs = s3fs.S3FileSystem(anon=True,\n",
    "                       client_kwargs= {'endpoint_url': 'https://s3.us-east-1.wasabisys.com'})\n",
    "\n",
    "ds = xr.open_zarr(fsspec.get_mapper(bucket,\n",
    "                                    client_kwargs=storage_options,\n",
    "                                    anon=True),\n",
    "                     consolidated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les simulations stochastiques ont été laminées par le logiciel HEC ResSim. Au total, 171 500 séries contenant 362 jours ont été calculés pour 34 réservoirs et 3 variables ont été extraites. Ceci implique environ 6,33 milliards de lignes de données (171 500 x 362 x 3 x 34). Le format zarr permet d'interagir efficacement avec cette quantité importante de données de manière optimale et avec une compression raisonnable pour limiter les besoins en bande passante (relativement à la quantité de données)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoir_list = ['ANGLIERS','BARK LAKE','BASKATONG','BRYSON',\n",
    "                  'CABONGA','CARILLON','CEDAR RAPID','CHAT FALLS',\n",
    "                  'CHELSEA','CHENAUX','CHUTE BELL','DES JOACHIMS',\n",
    "                  'DOZOIS','FARMERS','HIGH FALLS','HULL 2','KAMANISKEG',\n",
    "                  'KIAMIKA','KIPAWA','LAC VICTORIA','LADY EVELYN',\n",
    "                  'LOWER NOTCH','MISTINIKON','MITCHINAMECUS',\n",
    "                  'MOUNTAIN CHUTE','OTTO HOLDEN','PAUGAN','PREMIERE CHUTE',\n",
    "                  'RABBIT LAKE','RAPIDE 15','RAPIDE 2','RAPIDE 7','RAPIDE DES ILES',\n",
    "                  'TEMISCAMINGUE']\n",
    "freq_list = [0.9, 0.95, 0.98, 0.99, 0.999, 0.9999]\n",
    "\n",
    "@dask.delayed\n",
    "def get_frequencies_index(reservoir_id, variable_type):\n",
    "    df = ds.sel(variable_type=variable_type, \n",
    "                reservoir_id=reservoir_id)\\\n",
    "       .max('date')\\\n",
    "       .value\\\n",
    "       .to_dataframe()\\\n",
    "       .dropna()\\\n",
    "       .sort_values('value')\n",
    "\n",
    "    empirical_probability = plotting_positions(range(0,df.shape[0]), alpha=0.4, beta=0.4)\n",
    "\n",
    "    indexes = [np.argmin(np.abs(np.array(empirical_probability)-freq)) for freq in freq_list]\n",
    "    return pd.DataFrame(list(df.iloc[indexes].index),\n",
    "                        columns=[reservoir_id],\n",
    "                        index = [str(x).split('.')[0] \n",
    "                                 for x in list(np.round(1/(1 - np.array(freq_list))))]).T.round(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_type='FLOW-IN'\n",
    "filename='s3://prsim/laminage/09995-settings/index_flow_in.csv'\n",
    "override = False\n",
    "\n",
    "if fs.exists(filename) and override == False:\n",
    "    with fs.open(filename) as f:\n",
    "        basins_freq_indexes_flow_in = pd.read_csv(f, index_col=0)\n",
    "else:\n",
    "    results=[]\n",
    "    for bv in reservoir_list:\n",
    "        results.append(get_frequencies_index(bv, variable_type))\n",
    "    results = dask.delayed(pd.concat)(results)\n",
    "    basins_freq_indexes_flow_in = client.persist(results).compute()\n",
    "\n",
    "    with fs.open(filename, 'w') as f:\n",
    "        basins_freq_indexes_flow_in.to_csv(f, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_type='ELEV'\n",
    "filename='s3://prsim/laminage/09995-settings/index_elev.csv'\n",
    "\n",
    "if fs.exists(filename) and override == False:\n",
    "    with fs.open(filename) as f:\n",
    "        basins_freq_indexes_elev = pd.read_csv(f, index_col=0)\n",
    "else:\n",
    "    results=[]\n",
    "    for bv in reservoir_list:\n",
    "        results.append(get_frequencies_index(bv, variable_type))\n",
    "    results = dask.delayed(pd.concat)(results)\n",
    "    basins_freq_indexes_elev = client.persist(results).compute()\n",
    "\n",
    "    with fs.open(filename, 'w') as f:\n",
    "        basins_freq_indexes_elev.to_csv(f, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse fréquentielle des séries stochastiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tableaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_values(ds,\n",
    "                     reservoir_id,\n",
    "                     variable_type,\n",
    "                     basins_freq_indexes):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    da = ds.sel(variable_type=variable_type,\n",
    "                reservoir_id=reservoir_id)\\\n",
    "           .where(ds.member_id.isin(basins_freq_indexes.loc[reservoir_id]),\n",
    "                  drop=True).max('date')\n",
    "    \n",
    "    return pd.DataFrame(np.array(sorted(da.value.values)),\n",
    "                        columns=[reservoir_id],\n",
    "                        index = [str(x).split('.')[0] \n",
    "                                 for x in list(np.round(1/(1 - np.array(freq_list))))]).T.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Débit entrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "variable_type = 'FLOW-IN'\n",
    "\n",
    "df = pd.concat([frequency_values(ds,\n",
    "                 reservoir_id,\n",
    "                 variable_type,\n",
    "                 basins_freq_indexes_flow_in) for reservoir_id in reservoir_list])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Débit sortants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_type = 'FLOW-OUT'\n",
    "\n",
    "df = pd.concat([frequency_values(ds,\n",
    "                 reservoir_id,\n",
    "                 variable_type,\n",
    "                 basins_freq_indexes_flow_in) for reservoir_id in reservoir_list])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Niveaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_type = 'ELEV'\n",
    "\n",
    "df = pd.concat([frequency_values(ds,\n",
    "                 reservoir_id,\n",
    "                 variable_type,\n",
    "                 basins_freq_indexes_flow_in) for reservoir_id in reservoir_list])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.defaults(\n",
    "    opts.Curve(\n",
    "        active_tools=['wheel_zoom','pan'],\n",
    "))\n",
    "\n",
    "\n",
    "def plot_hydrographs(ds,\n",
    "                     reservoir_id,\n",
    "                     freq_value,\n",
    "                     variable_type_select,\n",
    "                     basins_freq_indexes):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    da = ds.sel(reservoir_id=reservoir_id)\\\n",
    "           .where(ds.member_id.isin(basins_freq_indexes.loc[reservoir_id, str(freq_value)]),\n",
    "                  drop=True)\n",
    "    \n",
    "    da['member_id'] = np.array([freq_value])\n",
    "    da = da.rename({'member_id':'periode_retour'}).value[:,0,:]\n",
    "    return (da.sel(variable_type='ELEV')\\\n",
    "              .hvplot(x='date',\n",
    "                      grid=True,\n",
    "                      by='variable_type',\n",
    "                      width=850) +\\\n",
    "            da.where(da.variable_type.isin(['FLOW-IN','FLOW-OUT']), \n",
    "                     drop=True)\\\n",
    "              .hvplot(x='date',\n",
    "                      grid=True,\n",
    "                      by='variable_type',\n",
    "                      width=850))\\\n",
    "            .opts(shared_axes=False, \n",
    "                  title=reservoir_id).cols(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Crues fréquentielles basées sur le débit entrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_d = pn.widgets.Select(name='RESERVOIR', options=reservoir_list)\n",
    "y_d = pn.widgets.Select(name='PERIODE DE RETOUR (basé sur le débit entrant maximum atteint)',\n",
    "                      options=[10, 20, 50, 100, 1000, 10000], value=10000, width=400)\n",
    "\n",
    "plot_d = plot_hydrographs(ds, x_d.value, y_d.value, 'FLOW-IN', basins_freq_indexes_flow_in)\n",
    "\n",
    "layout_d = pn.Column(pn.WidgetBox(x_d),\n",
    "                     pn.WidgetBox(y_d), \n",
    "                     plot_d)\n",
    "\n",
    "def update(event):\n",
    "    layout_d[2] = plot_hydrographs(ds, x_d.value, y_d.value, 'FLOW-IN', basins_freq_indexes_flow_in)\n",
    "\n",
    "x_d.param.watch(update, 'value')\n",
    "y_d.param.watch(update, 'value')\n",
    "\n",
    "layout_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Crues fréquentielles basées sur le niveau maximal atteint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_n = pn.widgets.Select(name='RESERVOIR', options=reservoir_list)\n",
    "y_n = pn.widgets.Select(name='PERIODE DE RETOUR (basé sur le niveau maximal atteint)',\n",
    "                      options=[10, 20, 50, 100, 1000, 10000], value=10000, width=400)\n",
    "\n",
    "plot_n = plot_hydrographs(ds, x_n.value, y_n.value, 'ELEV', basins_freq_indexes_elev)\n",
    "\n",
    "layout_n = pn.Column(pn.WidgetBox(x_n),\n",
    "                     pn.WidgetBox(y_n), \n",
    "                     plot_n)\n",
    "\n",
    "def update_n(event):\n",
    "    layout_n[2] = plot_hydrographs(ds, x_n.value, y_n.value, 'ELEV', basins_freq_indexes_elev)\n",
    "\n",
    "x_n.param.watch(update_n, 'value')\n",
    "y_n.param.watch(update_n, 'value')\n",
    "\n",
    "layout_n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laminage",
   "language": "python",
   "name": "laminage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
